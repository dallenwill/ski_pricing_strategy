{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    \n",
    "# Ski Pricing Strategy     \n",
    "# 5.0 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Table of Contents <a id=\"5.1_Table_of_Contents\"></a>\n",
    "* [5.1 Table of Contents](#5.1_Table_of_Contents)\n",
    "* [5.2 Introduction](#5.2_Introduction)\n",
    "* [5.3 Library Imports](#5.3_Library_Imports)\n",
    "* [5.4 Data Loading](#5.4_Data_Loading)\n",
    "* [5.5 Model Training](#5.5_Model_Training)\n",
    "  * [5.5.1 Linear Regression Models](#5.5.1_Linear_Regression_Models)\n",
    "  * [5.5.2 Tree-Based Models](#5.5.2_Tree_Based_Models)\n",
    "* [5.6 Model Tuning](#5.6_Model_Tuning)\n",
    "* [5.7 Final Model](#5.7_Final_Model)\n",
    "* [5.8 Summary](#5.8_Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Introduction <a id=\"5.2_Introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds predictive models for ski resort weekend ticket prices using the processed and feature-engineered dataset.\n",
    "We’ll start by training baseline and advanced models, evaluate them using R², RMSE, and MAE, and select the model that offers the best trade-off between performance and generalization.\n",
    "\n",
    "At the end:\n",
    "\n",
    "The final model and evaluation metrics will be saved for reuse in the next notebook (sys_06_model_evaluation.ipynb).\n",
    "\n",
    "The trained model will be applied to estimate Big Mountain Resort’s optimal price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Library Imports <a id=\"5.3_Library_Imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from joblib import load, dump\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Model fine-tuning\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Data Loading <a id=\"5.4_Data_Loading\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n",
      "Train: (216, 92) | Val: (55, 92)\n",
      "y_train mean: 64.32\n"
     ]
    }
   ],
   "source": [
    "# load artifacts, training set, validation set and target resort\n",
    "\n",
    "art = Path(\"../artifacts\")\n",
    "\n",
    "X_train = np.load(art / \"X_train_tf.npy\")\n",
    "X_val   = np.load(art / \"X_val_tf.npy\")\n",
    "y_train = pd.read_csv(art / \"y_train.csv\").squeeze()\n",
    "y_val   = pd.read_csv(art / \"y_val.csv\").squeeze()\n",
    "\n",
    "feature_names = pd.read_csv(art / \"feature_names.csv\").squeeze().tolist()\n",
    "\n",
    "print(\"Data Loaded\")\n",
    "print(\"Train:\", X_train.shape, \"| Val:\", X_val.shape)\n",
    "print(\"y_train mean:\", round(y_train.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Model Training <a id=\"5.5_Model_Training\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is a regression problem. The goal is to recommend an appropriate price for the target resort based on its features. Linear models are first applied, including **Linear Regression**, **Ridge Regression**, and **Lasso Regression**. Tree-based models—such as **Decision Trees**, **Random Forests**, and **Gradient Boosting Regressors**—are then used to capture more complex patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an evalation metric\n",
    "def evaluate(model, X_val, y_val):\n",
    "    preds = model.predict(X_val)\n",
    "    \n",
    "    mae = mean_absolute_error(y_val, preds)\n",
    "    mse = mean_squared_error(y_val, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_val, preds)\n",
    "    \n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 Linear Regression Models <a id=\"5.5.1_Linear_Regression_Models\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results:\n",
      "  MAE:  7.842\n",
      "  RMSE: 10.917\n",
      "  R2:   0.782\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "lr_mae, lr_rmse, lr_r2 = evaluate(lr_model, X_val, y_val)\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"  MAE:  {lr_mae:.3f}\")\n",
    "print(f\"  RMSE: {lr_rmse:.3f}\")\n",
    "print(f\"  R2:   {lr_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Results:\n",
      "  MAE:  7.633\n",
      "  RMSE: 10.612\n",
      "  R2:   0.794\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "ridge_mae, ridge_rmse, ridge_r2 = evaluate(ridge_model, X_val, y_val)\n",
    "print(\"Ridge Regression Results:\")\n",
    "print(f\"  MAE:  {ridge_mae:.3f}\")\n",
    "print(f\"  RMSE: {ridge_rmse:.3f}\")\n",
    "print(f\"  R2:   {ridge_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Results:\n",
      "  MAE:  7.847\n",
      "  RMSE: 10.913\n",
      "  R2:   0.782\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=0.001)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "lasso_mae, lasso_rmse, lasso_r2 = evaluate(lasso_model, X_val, y_val)\n",
    "print(\"Lasso Regression Results:\")\n",
    "print(f\"  MAE:  {lasso_mae:.3f}\")\n",
    "print(f\"  RMSE: {lasso_rmse:.3f}\")\n",
    "print(f\"  R2:   {lasso_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Regression Results:\n",
      "  MAE:  7.555\n",
      "  RMSE: 10.958\n",
      "  R2:   0.780\n"
     ]
    }
   ],
   "source": [
    "#ElasticNet Regression\n",
    "en_model = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=17)\n",
    "en_model.fit(X_train, y_train)\n",
    "\n",
    "en_mae, en_rmse, en_r2 = evaluate(en_model, X_val, y_val)\n",
    "\n",
    "print(\"ElasticNet Regression Results:\")\n",
    "print(f\"  MAE:  {en_mae:.3f}\")\n",
    "print(f\"  RMSE: {en_rmse:.3f}\")\n",
    "print(f\"  R2:   {en_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "```text\n",
    "Model                   MAE       RMSE      R²\n",
    "-------------------------------------------------\n",
    "Linear Regression      7.842     10.917    0.782\n",
    "Ridge Regression*      7.633     10.612    0.794\n",
    "Lasso Regression       7.847     10.913    0.782\n",
    "ElasticNet Regression  7.555     10.958    0.780\n",
    "\n",
    "Ridge Regression is the best linear model, showing the highest R², the lowest RMSE, and a relatively low MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 Tree-Based Models <a id=\"5.5.2_Tree_Based_Models\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Results:\n",
      "  MAE:  13.836\n",
      "  RMSE: 18.536\n",
      "  R2:   0.372\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(\n",
    "    max_depth=None,\n",
    "    random_state=17\n",
    ")\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_mae, dt_rmse, dt_r2 = evaluate(dt_model, X_val, y_val)\n",
    "\n",
    "print(\"Decision Tree Regression Results:\")\n",
    "print(f\"  MAE:  {dt_mae:.3f}\")\n",
    "print(f\"  RMSE: {dt_rmse:.3f}\")\n",
    "print(f\"  R2:   {dt_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Results:\n",
      "  MAE:  9.428\n",
      "  RMSE: 13.148\n",
      "  R2:   0.684\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    random_state=17,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_mae, rf_rmse, rf_r2 = evaluate(rf_model, X_val, y_val)\n",
    "\n",
    "print(\"Random Forest Regression Results:\")\n",
    "print(f\"  MAE:  {rf_mae:.3f}\")\n",
    "print(f\"  RMSE: {rf_rmse:.3f}\")\n",
    "print(f\"  R2:   {rf_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Results:\n",
      "  MAE:  8.204\n",
      "  RMSE: 11.439\n",
      "  R2:   0.761\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Regressor\n",
    "gb_model = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=17\n",
    ")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_mae, gb_rmse, gb_r2 = evaluate(gb_model, X_val, y_val)\n",
    "\n",
    "print(\"Gradient Boosting Regression Results:\")\n",
    "print(f\"  MAE:  {gb_mae:.3f}\")\n",
    "print(f\"  RMSE: {gb_rmse:.3f}\")\n",
    "print(f\"  R2:   {gb_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "```text\n",
    "Model                     MAE        RMSE       R²\n",
    "-------------------------------------------------------\n",
    "Decision Tree            13.836     18.536     0.372\n",
    "Random Forest             9.428     13.148     0.694\n",
    "Gradient Boosting         8.204     11.439     0.761\n",
    "\n",
    "Gradient Boosting is the best tree-based model, achieving the lowest MAE and RMSE and the highest R². However, the best model is still Regid Regression, which outperforms all other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Model Tuning <a id=\"5.6_Model_Tuning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 100\n",
      "Best CV RMSE: 13.233398467559041\n",
      "Tuned Ridge Regression on validation set:\n",
      "  MAE:  8.374\n",
      "  RMSE: 11.601\n",
      "  R2:   0.754\n"
     ]
    }
   ],
   "source": [
    "# Use Cross-Validation to fine tune Regid Regression\n",
    "\n",
    "# 1. Model\n",
    "ridge = Ridge()\n",
    "\n",
    "# 2. Hyperparameter grid\n",
    "param_grid = {\n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 50, 100]\n",
    "}\n",
    "\n",
    "# 3. Cross-validation setup (5-fold)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "# 4. Grid search + CV together\n",
    "grid = GridSearchCV(\n",
    "    estimator=ridge,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_squared_error\",  # we will convert to RMSE later\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha:\", grid.best_params_[\"alpha\"])\n",
    "print(\"Best CV RMSE:\", np.sqrt(-grid.best_score_))\n",
    "\n",
    "# 5. Evaluate the best model on validation set\n",
    "best_ridge = grid.best_estimator_\n",
    "mae, rmse, r2 = evaluate(best_ridge, X_val, y_val)\n",
    "\n",
    "print(\"Tuned Ridge Regression on validation set:\")\n",
    "print(f\"  MAE:  {mae:.3f}\")\n",
    "print(f\"  RMSE: {rmse:.3f}\")\n",
    "print(f\"  R2:   {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "```text\n",
    "Model                       MAE       RMSE      R²\n",
    "---------------------------------------------------------\n",
    "Ridge Regression (alpha=1)  7.633     10.612    0.794\n",
    "Tuned Ridge (alpha=100)     8.374     11.601    0.754\n",
    "\n",
    "The original Ridge Regression model with alpha = 1 provides the strongest performance among the Ridge configurations. It achieves the lowest RMSE, the highest R², and a lower MAE compared to the tuned model. The tuned Ridge Regression with alpha = 100, selected through cross-validation, shows weaker performance on the validation set, indicating that heavier regularization does not improve prediction accuracy for this dataset. Therefore, Ridge Regression with alpha = 1 is selected as the final linear model, as it offers the best overall balance of error and model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Final Model <a id=\"5.7_Final_Model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model trained on ALL available labeled data.\n"
     ]
    }
   ],
   "source": [
    "# Combine train + val into final training set\n",
    "X_final = np.concatenate([X_train, X_val])\n",
    "y_final = pd.concat([y_train, y_val])\n",
    "\n",
    "# Train final Ridge model\n",
    "final_model = Ridge(alpha=1)\n",
    "final_model.fit(X_final, y_final)\n",
    "\n",
    "print(\"Final model trained on ALL available labeled data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target features shape: (1, 92)\n"
     ]
    }
   ],
   "source": [
    "# load features of target resort\n",
    "X_tgt = np.load(art / \"X_tgt_tf.npy\")\n",
    "print(\"Target features shape:\", X_tgt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Ticket Price: 94.58\n"
     ]
    }
   ],
   "source": [
    "# Predict ticket price for target resort\n",
    "y_tgt_pred = final_model.predict(X_tgt)\n",
    "\n",
    "print(\"Predicted Ticket Price:\", round(float(y_tgt_pred[0]), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Summary<a id='5.8_Summary'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final Ridge Regression model (α = 1), trained on all available data, predicts a recommended ticket price of 94.58 dollar for the target resort.\n",
    "The resort’s current ticket price is 81 dollar, which is approximately $13.58 lower than the model’s estimated optimal value.\n",
    "\n",
    "This indicates that the resort may be underpricing relative to the historical relationships between features such as weather conditions, demand indicators, seasonality, and other engineered attributes.\n",
    "Adjusting the price closer to the model’s recommendation could potentially improve revenue while remaining consistent with past pricing patterns and market behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final model saved to: ../artifacts/final_model.joblib\n"
     ]
    }
   ],
   "source": [
    "#SaveArtifacts\n",
    "dump(final_model, art / \"final_model.joblib\")\n",
    "print(\"✅ Final model saved to:\", art / \"final_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ski_pricing_strategy)",
   "language": "python",
   "name": "ski_pricing_strategy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
